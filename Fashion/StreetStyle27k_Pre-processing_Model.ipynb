{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using the same code found in.\n",
    "https://github.com/fellowship/platform-demos2/blob/master/fashion-apparel/streetstyle/ss27k_preprocess.py\n",
    "\n",
    "\"\"\"\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import fastai\n",
    "from tqdm import tqdm\n",
    "import matplotlib.patches as patches\n",
    "#from google.colab import drive\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'fastai version is {fastai.__version__}')\n",
    "#drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the directory location\n",
    "#The processed_FN will be the cropped manifest\n",
    "STREETSTYLE_DIR = \"/gdrive/My Drive/streetstyle27k_cropped\"\n",
    "MANIFEST_FN = \"streetstyle27k.manifest\"\n",
    "IMAGES_PATH = \"streetstyle27k\"\n",
    "PROCESSED_FN = \"streetstyle27k.processed.manifest\"\n",
    "labels = pd.read_csv(os.path.join(STREETSTYLE_DIR, MANIFEST_FN))\n",
    "print(\"Found {} entries in {}\".format(len(labels), MANIFEST_FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['clothing_pattern', 'major_color',\n",
    "       'wearing_necktie', 'collar_presence', 'wearing_scarf', 'sleeve_length',\n",
    "       'neckline_shape', 'clothing_category', 'wearing_jacket', 'wearing_hat',\n",
    "       'wearing_glasses', 'multiple_layers']\n",
    "# Replacing spaces with \"_\", converting all labels to lower case labels, NA to no label\n",
    "# replacing the more_than_1_color label to multicolored\n",
    "for col in labels.columns:\n",
    "    if col in set(label_cols):\n",
    "        labels[col] = (labels[col].str.lower()\n",
    "                                  .str.replace(\" \", \"_\")\n",
    "                                  .str.replace(\"more_than_1_color\", \"multicolored\")\n",
    "                                  .fillna(\"no_label\"))\n",
    "        \n",
    "print(labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "do_cropping = True \n",
    "for _, item in labels[[\"url\", \"x1\", \"x2\", \"y1\", \"y2\"]].iterrows():\n",
    "    \n",
    "    uri = item[\"url\"]\n",
    "    fn = os.path.basename(uri)\n",
    "    # The path (url)of each image of the images in the manifest starts with the folders its stored e.g. 20f,20d.\n",
    "    img_path = os.path.join(STREETSTYLE_DIR, IMAGES_PATH, fn[0], fn[1], fn[2], fn)\n",
    "    cropped_img_path = img_path.replace(\"/\" + IMAGES_PATH + \"/\", \"/\" + IMAGES_PATH + \"_cropped/\")\n",
    "    if do_cropping and not os.path.exists(cropped_img_path):\n",
    "        bbox = item[\"x1\"], item[\"y1\"], item[\"x2\"], item[\"y2\"]\n",
    "        im = Image.open(img_path).crop(bbox)\n",
    "        os.makedirs(os.path.dirname(cropped_img_path), exist_ok=True)\n",
    "        im.save(cropped_img_path)\n",
    "    images.append(cropped_img_path.replace(\"{}/\".format(STREETSTYLE_DIR), \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[\"images\"] = images\n",
    "fastai_labels = []\n",
    "\n",
    "for _, item in labels[label_cols].iterrows():\n",
    "    #print(item.tolist())\n",
    "    item = [\"{}_{}\".format(c, v) for c, v in zip(label_cols, item.tolist())]\n",
    "    fastai_labels.append(\" \".join(item))\n",
    "labels[\"fastai\"] = fastai_labels\n",
    "\n",
    "labels[[\"images\", \"fastai\"]].to_csv(os.path.join(STREETSTYLE_DIR, PROCESSED_FN), index=False)\n",
    "print(\"Writing csv file to {}\".format(os.path.join(STREETSTYLE_DIR, PROCESSED_FN)))\n",
    "labels.to_csv(\"streetstyle.preprocess.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.imports import *\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "STREETSTYLE_DIR = \"/gdrive/My Drive/streetstyle27k_cropped\"\n",
    "MANIFEST_FN = \"streetstyle27k.manifest\"\n",
    "IMAGES_PATH = \"streetstyle27k\"\n",
    "PROCESSED_FN = \"streetstyle27k.processed.manifest\"\n",
    "labels = pd.read_csv(os.path.join(STREETSTYLE_DIR, MANIFEST_FN))\n",
    "print(\"Found {} entries in {}\".format(len(labels), MANIFEST_FN))\n",
    "categories = ['clothing_pattern', 'major_color', 'wearing_necktie', 'collar_presence', \n",
    "              'wearing_scarf', 'sleeve_length', 'neckline_shape', 'clothing_category', \n",
    "              'wearing_jacket', 'wearing_hat', 'wearing_glasses', 'multiple_layers']\n",
    "\n",
    "\n",
    "np.random.seed(1254)\n",
    "torch.manual_seed(1254)\n",
    "\n",
    "\n",
    "\n",
    "basedir = Path(STREETSTYLE_DIR)\n",
    "csvpath = 'streetstyle.preprocess.csv'\n",
    "print(csvpath)\n",
    "\n",
    "ds_tfms = get_transforms()\n",
    "input_size = (336, 336)\n",
    "df = pd.read_csv(csvpath)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = [3,10]\n",
    "lrs_list =[1e-2, 5e-6]\n",
    "do_lrfind = True\n",
    "import torchvision.models as models\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "#inception = models.inception_v3(pretrained=True)\n",
    "#vgg16 = models.vgg16(pretrained=True)\n",
    "modelname =  \"baseline\"\n",
    "for c in categories[0:1]:\n",
    "    print(\"Network for {}\".format(c))\n",
    "    df_category = df[[\"images\", c]]\n",
    "    df_category = df_category[~df_category[c].isna()]\n",
    "    print(df_category.head())\n",
    "    data = (ImageList.from_df(df_category, path=basedir)\n",
    "                     .split_by_rand_pct(0.2)\n",
    "                     .label_from_df()\n",
    "                     .transform(ds_tfms, size=input_size)\n",
    "                     .databunch(bs=16)\n",
    "                     .normalize(imagenet_stats))\n",
    "    #print(data)\n",
    "    #learn = Learner(data, resnet18, metrics=[accuracy], callback_fns=[callbacks.CSVLogger])\n",
    "    learn = cnn_learner(data, models.resnet34, metrics=[accuracy], callback_fns=[callbacks.CSVLogger])\n",
    "    learn.freeze()\n",
    "    for i, (epochs_i, lrs_i) in enumerate(zip(epochs_list, lrs_list)):\n",
    "        if do_lrfind:\n",
    "            print(\"Searching for optimal learning rates....\")\n",
    "            learn.lr_find()\n",
    "            learn.recorder.plot()\n",
    "            plt.savefig(\"lrfinder_{}_{}_{}.png\".format(modelname, c, sum(epochs_list[:i+1])))\n",
    "            if i != 0:\n",
    "                learn.load(\"{}_{}_{}epochs\".format(modelname, c, sum(epochs_list[:i]))) #fixed to i instead of i+1\n",
    "        learn.fit_one_cycle(epochs_i, lrs_i)\n",
    "        learn.save(\"{}_{}_{}epochs\".format(modelname, c, sum(epochs_list[:i+1])))\n",
    "        learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr=slice(1e-7,1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
